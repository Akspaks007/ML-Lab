{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "sybgbm6iP03i"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import math\n",
        "from collections import Counter\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv(\"/content/spam.csv\",)\n",
        "data.columns = ['Category', 'Message']\n",
        "data['Category'] = data['Category'].map({'ham': 0, 'spam': 1})"
      ],
      "metadata": {
        "id": "VJXJleZAWs_8"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(data['Message'], data['Category'], test_size=0.2, random_state=42)\n",
        "\n",
        "class CountVectorizerCustom:\n",
        "\n",
        "  def fit(self, documents):\n",
        "    vocab = set()\n",
        "    for doc in documents:\n",
        "      for word in doc.lower().split():\n",
        "        vocab.add(word)\n",
        "    self.vocab = {word: idx for idx, word in enumerate(sorted(vocab))}\n",
        "    return self\n",
        "\n",
        "\n",
        "  def transform(self, documents):\n",
        "    rows = []\n",
        "    for doc in documents:\n",
        "      vec = [0] * len(self.vocab)\n",
        "      for word in doc.lower().split():\n",
        "        if word in self.vocab:\n",
        "          vec[self.vocab[word]] += 1\n",
        "      rows.append(vec)\n",
        "    return np.array(rows)\n",
        "\n",
        "class TfidfVectorizerCustom:\n",
        "  def fit(self, documents):\n",
        "    self.docs = [doc.lower().split() for doc in documents]\n",
        "    self.vocab = {word: idx for idx, word in enumerate(sorted(set(word for doc in self.docs for word in doc)))}\n",
        "    self.idf = {}\n",
        "    N = len(self.docs)\n",
        "    for word in self.vocab:\n",
        "      df = sum(1 for doc in self.docs if word in doc)\n",
        "      self.idf[word] = math.log((N + 1) / (df + 1)) + 1\n",
        "    return self\n",
        "\n",
        "\n",
        "  def transform(self, documents):\n",
        "    rows = []\n",
        "    for doc in documents:\n",
        "      tf = Counter(doc.lower().split())\n",
        "      vec = [0] * len(self.vocab)\n",
        "      for word, count in tf.items():\n",
        "        if word in self.vocab:\n",
        "          vec[self.vocab[word]] = (count / len(doc)) * self.idf[word]\n",
        "      rows.append(vec)\n",
        "    return np.array(rows)\n",
        "\n",
        "class MultinomialNBCustom:\n",
        "  def __init__(self, alpha=1.0):\n",
        "    self.alpha = alpha\n",
        "\n",
        "\n",
        "  def fit(self, X, y):\n",
        "    self.classes = np.unique(y)\n",
        "    n_features = X.shape[1]\n",
        "    self.class_priors = {}\n",
        "    self.likelihoods = {}\n",
        "\n",
        "\n",
        "    for c in self.classes:\n",
        "      X_c = X[y == c]\n",
        "      self.class_priors[c] = X_c.shape[0] / X.shape[0]\n",
        "      word_counts = np.sum(X_c, axis=0) + self.alpha\n",
        "      self.likelihoods[c] = word_counts / (np.sum(word_counts))\n",
        "    return self\n",
        "\n",
        "\n",
        "  def predict(self, X):\n",
        "    preds = []\n",
        "    for x in X:\n",
        "      class_scores = {}\n",
        "      for c in self.classes:\n",
        "        log_prob = np.log(self.class_priors[c])\n",
        "        log_prob += np.sum(x * np.log(self.likelihoods[c]))\n",
        "        class_scores[c] = log_prob\n",
        "      preds.append(max(class_scores, key=class_scores.get))\n",
        "    return np.array(preds)\n"
      ],
      "metadata": {
        "id": "WeIcG1hAYOWR"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_and_evaluate(vectorizer, X_train, X_test, y_train, y_test):\n",
        "    vectorizer.fit(X_train)\n",
        "    X_train_vec = vectorizer.transform(X_train)\n",
        "    X_test_vec = vectorizer.transform(X_test)\n",
        "\n",
        "    model = MultinomialNBCustom(alpha=1.0)\n",
        "    model.fit(X_train_vec, y_train.values)\n",
        "    y_pred = model.predict(X_test_vec)\n",
        "\n",
        "    acc = accuracy_score(y_test, y_pred)\n",
        "    prec = precision_score(y_test, y_pred)\n",
        "    rec = recall_score(y_test, y_pred)\n",
        "    f1 = f1_score(y_test, y_pred)\n",
        "    cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "    print(f\"\\nUsing {vectorizer.__class__.__name__}:\")\n",
        "    print(f\"Accuracy: {acc:.4f}\")\n",
        "    print(f\"Precision: {prec:.4f}\")\n",
        "    print(f\"Recall: {rec:.4f}\")\n",
        "    print(f\"F1-score: {f1:.4f}\")\n",
        "    print(\"Confusion Matrix:\")\n",
        "    print(cm)\n",
        "    print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred, target_names=[\"Ham\", \"Spam\"]))"
      ],
      "metadata": {
        "id": "Mkz51ISOa3J2"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "count_vec = CountVectorizerCustom()\n",
        "train_and_evaluate(count_vec, X_train, X_test, y_train, y_test)\n",
        "\n",
        "\n",
        "tfidf_vec = TfidfVectorizerCustom()\n",
        "train_and_evaluate(tfidf_vec, X_train, X_test, y_train, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6g8iuxnIbKlt",
        "outputId": "b9f7be8b-f430-46d1-e305-fb78639027f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Using CountVectorizerCustom:\n",
            "Accuracy: 0.9865\n",
            "Precision: 1.0000\n",
            "Recall: 0.8993\n",
            "F1-score: 0.9470\n",
            "Confusion Matrix:\n",
            "[[966   0]\n",
            " [ 15 134]]\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "         Ham       0.98      1.00      0.99       966\n",
            "        Spam       1.00      0.90      0.95       149\n",
            "\n",
            "    accuracy                           0.99      1115\n",
            "   macro avg       0.99      0.95      0.97      1115\n",
            "weighted avg       0.99      0.99      0.99      1115\n",
            "\n"
          ]
        }
      ]
    }
  ]
}